{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python35\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "e:\\python35\\lib\\site-packages\\sklearn\\grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import cross_validation\n",
    "from sklearn.grid_search import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ds = pd.read_csv('../../data/ml4/train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ds_test = pd.read_csv('../../data/ml4/test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictors = [x for x in ds.columns if x not in ['connection_id','target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def modelfitxg(alg,dtrain,predictors,useTrainCV=False,cv_folds=5,early_stopping_rounds=50):\n",
    "    \n",
    "    if useTrainCV:\n",
    "        \n",
    "        xgb_params = alg.get_xgb_params()\n",
    "        xgb_params['num_class'] = 3\n",
    "        print(xgb_params)\n",
    "        xgtrain = xgb.DMatrix(dtrain[predictors].values,label=dtrain['target'].values)\n",
    "        print('prepared Dmatrix')\n",
    "        cvresult = xgb.cv(xgb_params, xgtrain, num_boost_round = alg.get_params()['n_estimators'],\n",
    "                         nfold=cv_folds,early_stopping_rounds=early_stopping_rounds)\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "        \n",
    "    # fit the algorithm\n",
    "        print(cvresult)\n",
    "    \n",
    "    print('Fitting Model')\n",
    "    alg.fit(dtrain[predictors],dtrain['target'],eval_metric='auc')\n",
    "    print('Model Fitted')\n",
    "    #predict training set\n",
    "    dtrain_predictions = alg.predict(dtrain[predictors])\n",
    "    dtrain_predprob = alg.predict_proba(dtrain[predictors])[:,1]\n",
    "    \n",
    "    print (\"Accuracy: %.4f\"%metrics.accuracy_score(dtrain['target'].values,dtrain_predictions))\n",
    "#     print (\"AUC Score (Train): %f\" % metrics.roc_auc_score(dtrain[''], dtrain_predprob))\n",
    "    \n",
    "    feat_imp = pd.Series(alg.booster().get_fscore()).sort_values(ascending=False)\n",
    "    feat_imp.plot(kind='bar',title='Feature Importance')\n",
    "    plt.ylabel('Feature Importance Score')\n",
    "    \n",
    "#     return cvresult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb1 = XGBClassifier(learning_rate=0.1,\n",
    "              n_estimators=500,\n",
    "              max_depth=6,\n",
    "              min_child_weight=5,\n",
    "              gamma=0.1,\n",
    "              subsample=0.9,\n",
    "              colsample_bytree=0.7,\n",
    "              objective='multi:softmax',\n",
    "              nthread=4,\n",
    "              reg_alpha = 0.05,\n",
    "              scale_pos_weight=1,\n",
    "              seed=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = xgb1.get_xgb_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'base_score': 0.5,\n",
       " 'colsample_bylevel': 1,\n",
       " 'colsample_bytree': 0.7,\n",
       " 'gamma': 2,\n",
       " 'learning_rate': 0.1,\n",
       " 'max_delta_step': 0,\n",
       " 'max_depth': 6,\n",
       " 'min_child_weight': 5,\n",
       " 'missing': None,\n",
       " 'n_estimators': 500,\n",
       " 'nthread': 4,\n",
       " 'num_class': 3,\n",
       " 'objective': 'multi:softmax',\n",
       " 'reg_alpha': 0.05,\n",
       " 'reg_lambda': 1,\n",
       " 'scale_pos_weight': 1,\n",
       " 'seed': 27,\n",
       " 'silent': 1,\n",
       " 'subsample': 0.9}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params['num_class'] = 3\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgtrain = xgb.DMatrix(ds[predictors].values,label=ds['target'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gridsearch_params = [\n",
    "    (max_depth, min_child_weight)\n",
    "    for max_depth in range(4,9)\n",
    "    for min_child_weight in range(4,8)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min_mae = float(\"Inf\")\n",
    "# 4894<min_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV with max_depth=4, min_child_weight=4\n",
      "\n",
      "\tMAE 0.2191606 for 119 rounds\n",
      "CV with max_depth=4, min_child_weight=6\n",
      "\tMAE 0.2191074 for 81 rounds\n",
      "CV with max_depth=5, min_child_weight=6\n",
      "\tMAE 0.2190838 for 100 rounds\n",
      "CV with max_depth=6, min_child_weight=4\n",
      "\tMAE 0.21906600000000004 for 60 rounds\n",
      "CV with max_depth=6, min_child_weight=5\n",
      "\tMAE 0.21904240000000003 for 73 rounds\n",
      "CV with max_depth=6, min_child_weight=6\n",
      "\tMAE 0.21906620000000002 for 63 rounds\n",
      "CV with max_depth=6, min_child_weight=7\n",
      "\tMAE 0.21910159999999998 for 60 rounds\n",
      "CV with max_depth=7, min_child_weight=4\n",
      "\tMAE 0.2190782 for 60 rounds\n",
      "CV with max_depth=7, min_child_weight=5\n",
      "\tMAE 0.21906019999999998 for 61 rounds\n",
      "CV with max_depth=7, min_child_weight=6\n",
      "\tMAE 0.2190722 for 72 rounds\n",
      "CV with max_depth=7, min_child_weight=7\n",
      "\tMAE 0.21907800000000002 for 58 rounds\n",
      "CV with max_depth=8, min_child_weight=4\n",
      "\tMAE 0.21907800000000002 for 69 rounds\n",
      "CV with max_depth=8, min_child_weight=5\n",
      "\tMAE 0.2191072 for 42 rounds\n",
      "CV with max_depth=8, min_child_weight=6\n"
     ]
    }
   ],
   "source": [
    "best_params = None\n",
    "for max_depth, min_child_weight in gridsearch_params:\n",
    "    print(\"CV with max_depth={}, min_child_weight={}\".format(\n",
    "                             max_depth,\n",
    "                             min_child_weight))\n",
    "\n",
    "    # Update our parameters\n",
    "    params['max_depth'] = max_depth\n",
    "    params['min_child_weight'] = min_child_weight\n",
    "\n",
    "    # Run CV\n",
    "    cvresult = xgb.cv(params, xgtrain, num_boost_round = xgb1.get_params()['n_estimators'],\n",
    "                         nfold=5,early_stopping_rounds=20)\n",
    "\n",
    "    # Update best MAE\n",
    "    mean_mae = cvresult['test-merror-mean'].min()\n",
    "    boost_rounds = cvresult['test-merror-mean'].argmin()\n",
    "    print(\"\\tMAE {} for {} rounds\".format(mean_mae, boost_rounds))\n",
    "    if mean_mae < min_mae:\n",
    "        min_mae = mean_mae\n",
    "        best_params = (max_depth,min_child_weight)\n",
    "\n",
    "print(\"Best params: {}, {}, MAE: {}\".format(best_params[0], best_params[1], min_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gridsearch_params = [\n",
    "    (max_depth, min_child_weight)\n",
    "    for max_depth in range(7,11)\n",
    "    for min_child_weight in range(6,9)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV with max_depth=7, min_child_weight=6\n",
      "\tMAE 0.2190782 for 46 rounds\n",
      "CV with max_depth=7, min_child_weight=7\n",
      "\tMAE 0.21907800000000002 for 58 rounds\n",
      "CV with max_depth=7, min_child_weight=8\n",
      "\tMAE 0.2190778 for 62 rounds\n",
      "CV with max_depth=8, min_child_weight=6\n",
      "\tMAE 0.21910779999999996 for 46 rounds\n",
      "CV with max_depth=8, min_child_weight=7\n",
      "\tMAE 0.21913100000000002 for 41 rounds\n",
      "CV with max_depth=8, min_child_weight=8\n",
      "\tMAE 0.2191724 for 33 rounds\n",
      "CV with max_depth=9, min_child_weight=6\n",
      "\tMAE 0.21914280000000003 for 24 rounds\n",
      "CV with max_depth=9, min_child_weight=7\n",
      "\tMAE 0.2190956 for 44 rounds\n",
      "CV with max_depth=9, min_child_weight=8\n",
      "\tMAE 0.21914899999999998 for 30 rounds\n",
      "CV with max_depth=10, min_child_weight=6\n",
      "\tMAE 0.2190956 for 43 rounds\n",
      "CV with max_depth=10, min_child_weight=7\n",
      "\tMAE 0.2190896 for 41 rounds\n",
      "CV with max_depth=10, min_child_weight=8\n",
      "\tMAE 0.2191252 for 28 rounds\n",
      "Best params: 7, 8, MAE: 0.2190778\n"
     ]
    }
   ],
   "source": [
    "best_params = None\n",
    "for max_depth, min_child_weight in gridsearch_params:\n",
    "    print(\"CV with max_depth={}, min_child_weight={}\".format(\n",
    "                             max_depth,\n",
    "                             min_child_weight))\n",
    "\n",
    "    # Update our parameters\n",
    "    params['max_depth'] = max_depth\n",
    "    params['min_child_weight'] = min_child_weight\n",
    "\n",
    "    # Run CV\n",
    "    cvresult = xgb.cv(params, xgtrain, num_boost_round = xgb1.get_params()['n_estimators'],\n",
    "                         nfold=5,early_stopping_rounds=10)\n",
    "\n",
    "    # Update best MAE\n",
    "    mean_mae = cvresult['test-merror-mean'].min()\n",
    "    boost_rounds = cvresult['test-merror-mean'].argmin()\n",
    "    print(\"\\tMAE {} for {} rounds\".format(mean_mae, boost_rounds))\n",
    "    if mean_mae < min_mae:\n",
    "        min_mae = mean_mae\n",
    "        best_params = (max_depth,min_child_weight)\n",
    "\n",
    "print(\"Best params: {}, {}, MAE: {}\".format(best_params[0], best_params[1], min_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_search_params2 = [(subsample,colsample)\n",
    "                       for subsample in [i/10 for i in range(9,11)]\n",
    "                      for colsample in [i/10 for i in range(7,11)]\n",
    "                      ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.7, 0.7),\n",
       " (0.7, 0.8),\n",
       " (0.7, 0.9),\n",
       " (0.7, 1.0),\n",
       " (0.8, 0.7),\n",
       " (0.8, 0.8),\n",
       " (0.8, 0.9),\n",
       " (0.8, 1.0),\n",
       " (0.9, 0.7),\n",
       " (0.9, 0.8),\n",
       " (0.9, 0.9),\n",
       " (0.9, 1.0),\n",
       " (1.0, 0.7),\n",
       " (1.0, 0.8),\n",
       " (1.0, 0.9),\n",
       " (1.0, 1.0)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_params2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV with max_depth=0.7, min_child_weight=0.7\n",
      "\tMAE 0.21911339999999999 for 86 rounds\n",
      "CV with max_depth=0.7, min_child_weight=0.8\n",
      "\tMAE 0.2190602 for 110 rounds\n",
      "CV with max_depth=0.7, min_child_weight=0.9\n",
      "\tMAE 0.21906019999999998 for 74 rounds\n",
      "CV with max_depth=0.7, min_child_weight=1.0\n",
      "\tMAE 0.21910179999999996 for 62 rounds\n",
      "CV with max_depth=0.8, min_child_weight=0.7\n",
      "\tMAE 0.21907800000000002 for 69 rounds\n",
      "CV with max_depth=0.8, min_child_weight=0.8\n",
      "\tMAE 0.21904839999999998 for 83 rounds\n",
      "CV with max_depth=0.8, min_child_weight=0.9\n",
      "\tMAE 0.2190664 for 68 rounds\n",
      "CV with max_depth=0.8, min_child_weight=1.0\n",
      "\tMAE 0.21907799999999997 for 75 rounds\n",
      "CV with max_depth=0.9, min_child_weight=0.7\n",
      "\tMAE 0.21903679999999998 for 87 rounds\n",
      "CV with max_depth=0.9, min_child_weight=0.8\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-c671f8b54880>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;31m# Run CV\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     cvresult = xgb.cv(params, xgtrain, num_boost_round = xgb1.get_params()['n_estimators'],\n\u001b[1;32m---> 13\u001b[1;33m                          nfold=5,early_stopping_rounds=20)\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;31m# Update best MAE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\python35\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mcv\u001b[1;34m(params, dtrain, num_boost_round, nfold, stratified, folds, metrics, obj, feval, maximize, early_stopping_rounds, fpreproc, as_pandas, verbose_eval, show_stdv, seed, callbacks)\u001b[0m\n\u001b[0;32m    398\u001b[0m                            evaluation_result_list=None))\n\u001b[0;32m    399\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mfold\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcvfolds\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 400\u001b[1;33m             \u001b[0mfold\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    401\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maggcv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcvfolds\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\python35\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, iteration, fobj)\u001b[0m\n\u001b[0;32m    217\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m         \u001b[1;34m\"\"\"\"Update the boosters for one iteration\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 219\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    220\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\python35\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m    804\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    805\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 806\u001b[1;33m             \u001b[0m_check_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXGBoosterUpdateOneIter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    807\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    808\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_params = None\n",
    "for subsample, colsample in grid_search_params2:\n",
    "    print(\"CV with max_depth={}, min_child_weight={}\".format(\n",
    "                             subsample,\n",
    "                             colsample))\n",
    "\n",
    "    # Update our parameters\n",
    "    params['subsample'] = subsample\n",
    "    params['colsample_bytree'] = colsample\n",
    "\n",
    "    # Run CV\n",
    "    cvresult = xgb.cv(params, xgtrain, num_boost_round = xgb1.get_params()['n_estimators'],\n",
    "                         nfold=5,early_stopping_rounds=20)\n",
    "\n",
    "    # Update best MAE\n",
    "    mean_mae = cvresult['test-merror-mean'].min()\n",
    "    boost_rounds = cvresult['test-merror-mean'].argmin()\n",
    "    print(\"\\tMAE {} for {} rounds\".format(mean_mae, boost_rounds))\n",
    "    if mean_mae < min_mae:\n",
    "        min_mae = mean_mae\n",
    "        best_params = (subsample,colsample)\n",
    "\n",
    "print(\"Best params: {}, {}, MAE: {}\".format(best_params[0], best_params[1], min_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV with max_depth=0.9, min_child_weight=0.7\n",
      "\tMAE 0.21903679999999998 for 87 rounds\n",
      "CV with max_depth=0.9, min_child_weight=0.8\n",
      "\tMAE 0.2190956 for 64 rounds\n",
      "CV with max_depth=0.9, min_child_weight=0.9\n",
      "\tMAE 0.2190722 for 62 rounds\n",
      "CV with max_depth=0.9, min_child_weight=1.0\n",
      "\tMAE 0.21911339999999999 for 46 rounds\n",
      "CV with max_depth=1.0, min_child_weight=0.7\n",
      "\tMAE 0.2190484 for 63 rounds\n",
      "CV with max_depth=1.0, min_child_weight=0.8\n"
     ]
    }
   ],
   "source": [
    "best_params = None\n",
    "for subsample, colsample in grid_search_params2:\n",
    "    print(\"CV with max_depth={}, min_child_weight={}\".format(\n",
    "                             subsample,\n",
    "                             colsample))\n",
    "\n",
    "    # Update our parameters\n",
    "    params['subsample'] = subsample\n",
    "    params['colsample_bytree'] = colsample\n",
    "\n",
    "    # Run CV\n",
    "    cvresult = xgb.cv(params, xgtrain, num_boost_round = xgb1.get_params()['n_estimators'],\n",
    "                         nfold=5,early_stopping_rounds=10)\n",
    "\n",
    "    # Update best MAE\n",
    "    mean_mae = cvresult['test-merror-mean'].min()\n",
    "    boost_rounds = cvresult['test-merror-mean'].argmin()\n",
    "    print(\"\\tMAE {} for {} rounds\".format(mean_mae, boost_rounds))\n",
    "    if mean_mae < min_mae:\n",
    "        min_mae = mean_mae\n",
    "        best_params = (subsample,colsample)\n",
    "\n",
    "print(\"Best params: {}, {}, MAE: {}\".format(best_params[0], best_params[1], min_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_search_params3 = [(subsample,colsample)\n",
    "                       for subsample in [0.8,0.85,0.9,0.95]\n",
    "                      for colsample in [0.7,0.75,0.8,0.85]\n",
    "                      ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV with subsample=0.8, colsample_bytree=0.7\n",
      "\tMAE 0.21907800000000002 for 69 rounds\n",
      "Mean MAE: 0.219528748571\n",
      "CV with subsample=0.8, colsample_bytree=0.75\n",
      "\tMAE 0.21914280000000003 for 59 rounds\n",
      "Mean MAE: 0.219614466667\n",
      "CV with subsample=0.8, colsample_bytree=0.8\n",
      "\tMAE 0.21904839999999998 for 83 rounds\n",
      "Mean MAE: 0.219432311905\n",
      "CV with subsample=0.8, colsample_bytree=0.85\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-dede573c8ad2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;31m# Run CV\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     cvresult = xgb.cv(params, xgtrain, num_boost_round = xgb1.get_params()['n_estimators'],\n\u001b[1;32m---> 13\u001b[1;33m                          nfold=5,early_stopping_rounds=10)\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;31m# Update best MAE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\python35\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mcv\u001b[1;34m(params, dtrain, num_boost_round, nfold, stratified, folds, metrics, obj, feval, maximize, early_stopping_rounds, fpreproc, as_pandas, verbose_eval, show_stdv, seed, callbacks)\u001b[0m\n\u001b[0;32m    398\u001b[0m                            evaluation_result_list=None))\n\u001b[0;32m    399\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mfold\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcvfolds\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 400\u001b[1;33m             \u001b[0mfold\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    401\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maggcv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcvfolds\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\python35\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, iteration, fobj)\u001b[0m\n\u001b[0;32m    217\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m         \u001b[1;34m\"\"\"\"Update the boosters for one iteration\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 219\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    220\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\python35\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m    804\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    805\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 806\u001b[1;33m             \u001b[0m_check_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXGBoosterUpdateOneIter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    807\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    808\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_params = None\n",
    "for subsample, colsample in grid_search_params3:\n",
    "    print(\"CV with subsample={}, colsample_bytree={}\".format(\n",
    "                             subsample,\n",
    "                             colsample))\n",
    "\n",
    "    # Update our parameters\n",
    "    params['subsample'] = subsample\n",
    "    params['colsample_bytree'] = colsample\n",
    "\n",
    "    # Run CV\n",
    "    cvresult = xgb.cv(params, xgtrain, num_boost_round = xgb1.get_params()['n_estimators'],\n",
    "                         nfold=5,early_stopping_rounds=10)\n",
    "\n",
    "    # Update best MAE\n",
    "    mean_mae = cvresult['test-merror-mean'].min()\n",
    "    boost_rounds = cvresult['test-merror-mean'].argmin()\n",
    "    print(\"\\tMAE {} for {} rounds\".format(mean_mae, boost_rounds))\n",
    "    print(\"Mean MAE:\",cvresult['test-merror-mean'].mean())\n",
    "    if mean_mae < min_mae:\n",
    "        min_mae = mean_mae\n",
    "        best_params = (subsample,colsample)\n",
    "\n",
    "print(\"Best params: {}, {}, MAE: {}\".format(best_params[0], best_params[1], min_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_search_params3 =[(0.8, 0.85),\n",
    " (0.85, 0.7),\n",
    " (0.85, 0.75),\n",
    " (0.85, 0.8),\n",
    " (0.85, 0.85),\n",
    " (0.9, 0.7),\n",
    " (0.9, 0.75),\n",
    " (0.9, 0.8),\n",
    " (0.9, 0.85),\n",
    " (0.95, 0.7),\n",
    " (0.95, 0.75),\n",
    " (0.95, 0.8),\n",
    " (0.95, 0.85)]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV with subsample=0.8, colsample_bytree=0.85\n",
      "\tMAE 0.21907799999999997 for 73 rounds\n",
      "Mean MAE: 0.219475962162\n",
      "CV with subsample=0.85, colsample_bytree=0.7\n",
      "\tMAE 0.21906019999999998 for 78 rounds\n",
      "Mean MAE: 0.219474982278\n",
      "CV with subsample=0.85, colsample_bytree=0.75\n",
      "\tMAE 0.2190426 for 79 rounds\n",
      "Mean MAE: 0.219463815\n",
      "CV with subsample=0.85, colsample_bytree=0.8\n",
      "\tMAE 0.21916639999999998 for 37 rounds\n",
      "Mean MAE: 0.219783647368\n",
      "CV with subsample=0.85, colsample_bytree=0.85\n",
      "\tMAE 0.21904240000000003 for 73 rounds\n",
      "Mean MAE: 0.219471575676\n",
      "CV with subsample=0.9, colsample_bytree=0.7\n",
      "\tMAE 0.21903679999999998 for 87 rounds\n",
      "Mean MAE: 0.219429736364\n",
      "CV with subsample=0.9, colsample_bytree=0.75\n",
      "\tMAE 0.21906620000000002 for 75 rounds\n",
      "Mean MAE: 0.219488671053\n",
      "CV with subsample=0.9, colsample_bytree=0.8\n",
      "\tMAE 0.2190956 for 64 rounds\n",
      "Mean MAE: 0.219501058462\n",
      "CV with subsample=0.9, colsample_bytree=0.85\n",
      "\tMAE 0.2191312 for 39 rounds\n",
      "Mean MAE: 0.219788395\n",
      "CV with subsample=0.95, colsample_bytree=0.7\n",
      "\tMAE 0.21909 for 73 rounds\n",
      "Mean MAE: 0.219520997297\n",
      "CV with subsample=0.95, colsample_bytree=0.75\n",
      "\tMAE 0.21908979999999997 for 61 rounds\n",
      "Mean MAE: 0.219581058065\n",
      "CV with subsample=0.95, colsample_bytree=0.8\n",
      "\tMAE 0.2190838 for 57 rounds\n",
      "Mean MAE: 0.219553437931\n",
      "CV with subsample=0.95, colsample_bytree=0.85\n",
      "\tMAE 0.2191194 for 42 rounds\n",
      "Mean MAE: 0.219752274419\n",
      "Best params: 0.9, 0.7, MAE: 0.21903679999999998\n"
     ]
    }
   ],
   "source": [
    "best_params = None\n",
    "for subsample, colsample in grid_search_params3:\n",
    "    print(\"CV with subsample={}, colsample_bytree={}\".format(\n",
    "                             subsample,\n",
    "                             colsample))\n",
    "\n",
    "    # Update our parameters\n",
    "    params['subsample'] = subsample\n",
    "    params['colsample_bytree'] = colsample\n",
    "\n",
    "    # Run CV\n",
    "    cvresult = xgb.cv(params, xgtrain, num_boost_round = xgb1.get_params()['n_estimators'],\n",
    "                         nfold=5,early_stopping_rounds=10)\n",
    "\n",
    "    # Update best MAE\n",
    "    mean_mae = cvresult['test-merror-mean'].min()\n",
    "    boost_rounds = cvresult['test-merror-mean'].argmin()\n",
    "    print(\"\\tMAE {} for {} rounds\".format(mean_mae, boost_rounds))\n",
    "    print(\"Mean MAE:\",cvresult['test-merror-mean'].mean())\n",
    "    if mean_mae < min_mae:\n",
    "        min_mae = mean_mae\n",
    "        best_params = (subsample,colsample)\n",
    "\n",
    "print(\"Best params: {}, {}, MAE: {}\".format(best_params[0], best_params[1], min_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Model\n",
      "Model Fitted\n",
      "Accuracy: 0.7819\n"
     ]
    }
   ],
   "source": [
    "modelfitxg(xgb1,ds,predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_targets = xgb1.predict(ds_test[predictors])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_connections = ds_test['connection_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat_imp = pd.Series(xgb1.booster().get_fscore()).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cat_20     1688\n",
       "cat_2       917\n",
       "cont_2      797\n",
       "cat_23      764\n",
       "cat_21      687\n",
       "cont_12     518\n",
       "cont_11     484\n",
       "cont_8      467\n",
       "cont_3      440\n",
       "cont_9      370\n",
       "cont_17     314\n",
       "cat_22      300\n",
       "cont_1      293\n",
       "cont_13     253\n",
       "cont_14     194\n",
       "cat_3       163\n",
       "cat_7       138\n",
       "cat_1       120\n",
       "cont_15     120\n",
       "cont_4       99\n",
       "cont_6       94\n",
       "cont_16      79\n",
       "cat_9        59\n",
       "cont_10      51\n",
       "cont_5       40\n",
       "cont_18      39\n",
       "cat_10       33\n",
       "cat_5        30\n",
       "cont_7       23\n",
       "cat_19       17\n",
       "cat_8        11\n",
       "cat_13        2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cat_20     1673\n",
       "cat_2       932\n",
       "cont_2      845\n",
       "cat_23      802\n",
       "cat_21      663\n",
       "cont_12     530\n",
       "cont_8      503\n",
       "cont_11     487\n",
       "cont_3      446\n",
       "cont_9      380\n",
       "cont_17     332\n",
       "cont_1      303\n",
       "cont_13     302\n",
       "cat_22      275\n",
       "cont_14     206\n",
       "cat_7       158\n",
       "cont_15     137\n",
       "cont_4      121\n",
       "cat_1       117\n",
       "cont_6      105\n",
       "cont_16     100\n",
       "cat_9        77\n",
       "cont_5       63\n",
       "cont_18      57\n",
       "cont_10      55\n",
       "cat_5        29\n",
       "cat_10       24\n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_search_params4 = [g for g in [0.5,0.6,0.7,0.8,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV with gamma=0\n",
      "\tMAE 0.21913739999999998 for 55 rounds\n",
      "Mean MAE: 0.219638396429\n",
      "CV with gamma=0.1\n",
      "\tMAE 0.21912499999999996 for 59 rounds\n",
      "Mean MAE: 0.219602306667\n",
      "CV with gamma=0.2\n",
      "\tMAE 0.2191312 for 55 rounds\n",
      "Mean MAE: 0.219636292857\n",
      "CV with gamma=0.3\n",
      "\tMAE 0.21920199999999998 for 36 rounds\n",
      "Mean MAE: 0.219870610811\n",
      "CV with gamma=0.4\n",
      "\tMAE 0.21912539999999997 for 69 rounds\n",
      "Mean MAE: 0.219537014286\n",
      "Best params: 0.1, MAE: 0.21912499999999996\n"
     ]
    }
   ],
   "source": [
    "best_params = None\n",
    "for gamma in grid_search_params4:\n",
    "    print(\"CV with gamma={}\".format(gamma))\n",
    "\n",
    "    # Update our parameters\n",
    "    params['gamma'] = gamma\n",
    "#     params['colsample_bytree'] = colsample\n",
    "\n",
    "    # Run CV\n",
    "    cvresult = xgb.cv(params, xgtrain, num_boost_round = xgb1.get_params()['n_estimators'],\n",
    "                         nfold=5,early_stopping_rounds=10)\n",
    "\n",
    "    # Update best MAE\n",
    "    mean_mae = cvresult['test-merror-mean'].min()\n",
    "    boost_rounds = cvresult['test-merror-mean'].argmin()\n",
    "    print(\"\\tMAE {} for {} rounds\".format(mean_mae, boost_rounds))\n",
    "    print(\"Mean MAE:\",cvresult['test-merror-mean'].mean())\n",
    "    if mean_mae < min_mae:\n",
    "        min_mae = mean_mae\n",
    "        best_params = gamma\n",
    "\n",
    "print(\"Best params: {}, MAE: {}\".format(best_params, min_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output = []\n",
    "for i in range(len(test_connections)):\n",
    "    output.append((test_connections[i],test_targets[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt('./ml4output9.csv',output,fmt='%s,%s',delimiter=',',header='connection_id,target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
